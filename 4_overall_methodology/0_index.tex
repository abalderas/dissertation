
% this file is called up by thesis.tex
% content in this file will be fed into the main document

%: ----------------------- introduction file header -----------------------
\begin{savequote}[50mm]
Historical methodology, as I see it, is a product of common sense applied to circumstances. 
\qauthor{Samuel E. Morison}
\end{savequote}


\chapter{Método para la evaluación de competencias genéricas}
\label{cha:Overall methodology}

% the code below specifies where the figures are stored
\ifpdf
    \graphicspath{{4_overall_methodology/figures/PNG/}{4_overall_methodology/figures/PDF/}{4_overall_methodology/figures/}}
\else
    \graphicspath{{4_overall_methodology/figures/EPS/}{4_overall_methodology/figures/}}
\fi


%------------------------------------------------------------------------- 

En este capítulo se propone un método para la evaluación de competencias genéricas a partir de indicadores obtenidos del registro de interacciones de los estudiantes con el VLE. El capítulo comienza con una introducción a las bases de la propuesta y una descripción de las características más relevantes del \emph{learning analytics}. Finalmente se describirá la metología propuesta, las técnicas con las que se aplican y las implementaciones que se han realizado.

\section{Introducción}

Se podria decir que hoy en día el VLE es una pieza fundamental en cualquier contexto en el que se impartan cursos. Mientras que en los cursos virtuales es el único entorno de trabajo posible, en los cursos presenciales actúa como soporte virtual de las clases. Pero en ambos casos ofrece el espacio para gestionar el material del curso, las actividades y los estudiantes. 

Los estudiantes pasan a diario por las páginas del VLE. Por una lado, habrá estudiantes que entren en el sistema varias veces al día a consultar cualquier novedad y que sólo permanezcan 20 segundos en el VLE. Mientras que por otro lado, habrá estudiantes que entren una vez a la semana pero estén dos horas navegando por el VLE. Y entre un tipo de estudiante y otro, habrá tantas maneras de actuar de los estudiantes en el VLE como estudiantes haya. 

Todos los movimientos de los estudiantes quedan almacenados en el registro del VLE y estos registros podrían ser analizados para comprender el proceso de aprendizaje que en el VLE se está desarrollando. El \emph{learning analytics} es un area de investigación del aprendizaje mejorado por la tecnologia (TEL, del inglés \emph{Technology Enhanced Learning}) que esta enfocado en el desarrollo de métodos para analizar y detectar patrones en los datos recogidos en los entornos educativos y aprovecharlo para mejorar el aprendizaje~\cite{chatti2014learning}. La propuesta de esta tesis es que a partir de este método, los profesores podrán utilizar patrones de comportamiento de los estudiantes, plasmado a partir de su actividad en el VLE, como indicadores del desempeño de los estudiantes en las competencias genéricas. 

Este capítulo continua con los requisitos de método, la descripción detallada del mismo y su implementación en diferentes actividades de aprendizaje.

\section{Requisitos}

El método debe cumplir una serie de requisitos que parten de los inconvenientes encontrados en la revisión de la literatura realizada en el capítulo \ref{cha:State of the Art} y que han sido resumidos en el capítulo \ref{cha:Problemas}. A continuación se describe cada uno de estos requisitos.

\paragraph*{Indicadores objetivos}

Los indicadores reflejarán los datos obtenidos directamente del registro del VLE, por lo que serán objetivos per sé. No ha lugar a consideraciones personales o interpretaciones inexactas de rúbricas cómo ocurría en la autoevaluación o evaluación entre iguales, dónde dos evaluaciones de un mismo trabajo realizada por personas diferentes podria tener calificaciones diferentes. En el caso de los indicadores obtenidos del registro del VLE, dos estudiantes que tienen los mismos datos en el registro tendrán en el mismo valor en el indicador, y ya sera cometido del profesor la interpretación que otorgue a ese indicador.

\paragraph*{Evaluación escalable}

El método para la evaluación de competencias genéricas deberá ser escalable y no podrá suponer al profesor un esfuerzo que éste no pueda abordar. Por eso, el método se alineará con las herramientas del VLE, el profesor podrá consultar los indicadores del registro que requiera para llevar a cabo sus evaluaciones y la información será devuelta en formatos que el profesor pueda visionar y exportar a otras herramientas.

\paragraph*{Propósito general}

El próposito del método es obtener indicadores del registro del VLE y que estos sean utilizados para evaluar competencias genéricas. Pero no estan orientados a una competencia genérica concreta, sino que la idea es que el profesor diseñe sus actividades en el VLE y que luego obtenga los indicadores para utilizarlos en la evaluación de la competencia genéricas que considere que los estudiantes han desempeñado en dicha tarea (y que queda reflejada en los indicadores). El profesor podria incluso utilizar los indicadores para evaluar competencias específicas si lo creyese oportuno. Pero en ningún caso este método tendrá como propósito una competencia y actividad concreta como ocurría, por ejemplo, con algunos juegos serios recogidos en el estado del arte.

\paragraph*{Coste asumible}

No será necesario que el profesor tenga un perfil informático u otro específico para poder realizar las consultas de los indicadores. La interfaz en la que se implemente el método será lo más usable y sencilla posible para que los profesores puedan utilizarla sin requerirles conocimientos técnicos.

\paragraph*{Diseño de evaluaciones}

El método deberá proporcionar al profesor la posibilidad de diseñar sus propias evaluaciones a partir de los indicadores. En el estado del arte nos encontramos con trabajos que obtenían sus evaluaciones a partir de los indicadores del VLE, pero éstos eran fijos. Es decir, cada competencia se evalúa con un indicador dado. Pero puede ocurrir que el profesor no utilice las actividades del VLE que proporcionen dichos indicadores o que utilice las actividades con un enfoque diferente. También podría ocurrir que quisiera combinar el resultado de un indicador con otro para obtener lo que él considerará un indicador válido de la competencia. 

En resumen, podemos decir que el método que se propone para evaluar competencias genéricas a partir de los registros de interacción del VLE será puesto a disposición del profesor en forma de una herramienta informática que se conecte al VLE utilizado en la asignatura. Mediante esta herramienta, los profesores podran diseñar evaluaciones a partir de indicadores objetivos obtenidos del VLE y aplicarlas a las competencias genéricas para las que ellos consideren que les son válidos.


%\section{Learning analytics}

%Este término ya apareció en capítulos anteriores, pero es necesario volver a traerlo y hablar más en profundidad sobre él ya que es la base del método presentado en estre trabajo. El \emph{learning analytics} es la medición, recopilación, análisis y presentación de datos sobre los estudiantes, sus contextos y las interacciones que allí se generan, con el fin de comprender el proceso de aprendizaje que se está desarrollando y optimizar los entornos en los que se produce~\cite{siemens2012learning}.

\section{Descripción}

El método para la evaluación de competencias genéricas a partir de los registros del VLE se basa en el \emph{ciclo de contraste de hipótesis}. Este ciclo será explicado a continuación junto con el conjunto de pasos que explican el método.

\begin{enumerate}
\item Los estudiantes comienzan a dejar constancia de su actividad en el VLE desde el momento en que se registran en el sistema. El registro lo almacena todo, tanto la participación activa del estudiante, escribiendo y respndiendo mensajes en los foros o enviando actividades, como la participación pasiva, cuando simplemente lee el foro o se descarga los apuntes. 
\item Los programas de las asignaturas incluyen las competencias genéricas de las que los estudiantes deben ser evaluados. Los profesores pueden plantear actividades en el VLE con la intención no solo de evaluar ciertas habilidades de los estudiantes, sino también para provocar o conocer cómo lo resuelven los estudiantes. El fin de conocer el modo de proceder de los estudiantes es encontrar patrones de comportamiento que puedan ser interpretados como un indicador del desempeño de alguna competencia genérica.
\item Para evaluar una competencia genérica dada, el profesor podrá diseñar una evaluación a partir de la información contenida en el registro del VLE. Aquí comienza el  \emph{ciclo de contraste de hipótesis}. Ese diseño será procesado por el sistema que implementa el método y que terminará devolviendo la información al profesor. El resultado de aplicar el diseño será un indicador que el profesor podrá utilizar para la evaluación de la competencia genérica.
\item También se puede dar el caso de que el profesor considere que el indicador no es válido para la evaluación de la competencia genérica. También puede que aunque le sea válido pero considere que un rediseño del mismo le permitará afinar más en cuánto al ojetivo de evaluación de competencia genérica que se marcó. El profesor podría diseñar una nueva evaluación a partir de la información contenida en el registro y así sucesivamente hasta que los resultados satisfagan su hipótesis, momento en el que termina el  \emph{ciclo de contraste de hipótesis}.
\end{enumerate}

\section{Implementaciones}

Hay diversos entornos en los que se pueden desarrollar actividades de aprendizaje. Para la implementación del método se seleccionaron tres entornos diferentes: el primer entorno fue un wiki, entorno de trabajo online donde los usuarios crean y editan el contenido de forma colaborativa; el segundo fue un VLE, entorno de aprendizaje virtual donde se alojan cursos virtuales; y el tercero un mundo virtual, donde los estudiantes afrontan situaciones de la vida real en un entorno de simulación virtual.

En los próximos apartados se describirá cada una de las herramientas implementadas para abordar el diseño de evaluaciones para estas actividades de aprendizaje.

%------------------------------------------------
\subsection{Wikis: AssessMediaWiki}

El uso educacional de los wikis para las experiencias de trabajo colaborativo mediante el uso de la tecnología está en auge debido a las numerosas ventajas que aporta sobre los modelos tradicionales~\cite{elgort2008wiki}. Algunas de las ventajas sobre los medios tradicionales, ya sean en formato impreso o en documentos digitales, es que estos no llevan un registro de ediciones, no permiten la colaboración distribuída y asincrona y no pueden ser monitorizados mientras son completados por el profesor.

Una de las características interesantes de los wikis es que no sólo almacenan la información de la versión final de cada documento, sino que también almacenan todas las versiones intermedias creadas como resultado de las contribuciones hechas por cada usuario~\cite{trentin2009using}. Para evaluar el trabajo final de un grupo de estudiantes en una página del wiki nos bastaría con leer la última versión de dicha página, como haciamos con los métodos tradicionales. Sin embargo, gracias a que los wikis mantienen un registro con las diferencias entre las ediciones consecutivas de las páginas, se podria utilizar dicha información como indicadores para la evaluación de diferentes competencias~\cite{ortega2011new}. Las páginas creadas de manera colaborativa podrían ser evaluadas considerando la contribución de cada autor y las dinámicas de grupo en la creación de la página en tiempo real. Por desgracia, realizar una evaluación detallada de cada contribución realizada en el wiki es imposible de abordar por la gran cantidad de trabajo que eso implica cuando el número de usuario en el wiki es elevado y participan activamente.

En un trabajo anterior se utilizó \emph{StatMediaWiki} (SMW)~\footnote{http://statmediawiki.forja.rediris.es/}, una herramienta que proporciona al profesor información cuantitativa sobre la distribución del trabajo de los estudiantes en las páginas del wiki, es decir, qué parte del trabajo realizado en una página del wiki corresponde a cada estudiante. A partir de esa información cuantitativa se evaluó la distribución del trabajo, el trabajo en equipo o el liderazgo. Sin embargo, el aspecto cualitativo quedó fuera, ya que el experimento sólo consideró el número, el momento y el tamaño de las contribuciones~\cite{palomo2014assessment}.

En este trabajo se propone una herramienta para realizar una evaluación escalable y cualitativa del trabajo realizado en el wiki. Para ello se creó \emph{AssessMediaWiki} (AMW), una aplicación web que proporciona procedimientos de autoevaluación, evaluación entre iguales y evaluación del profesor a partir de una rúbrica para evaluar a los estudiantes.

\subsubsection{Metodología para la evaluación del trabajo en el wiki}

En la figura~\ref{fig:AmwDiagram} puede verse un diagrama de flujo de trabajo que muestra el proceso de evaluación realizado sobre una página del wiki en la que participan varios estudiantes y el profesor. Este flujo de trabajo tiene tres fases: una primera fase en la que los estudiantes realizan sus trabajos en las páginas del wiki, una segunda fase de evaluación y una tercera fase de revisión del profesor.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.28]{AmwDiagram.png}
  \end{center}
  \caption{Ejemplo de flujo de trabajo para la evaluación cualitativa del wiki utilizando AMW}
  \label{fig:AmwDiagram}
\end{figure}

\paragraph*{Desarrollo del trabajo en el wiki}

Esta fase se representa en la columna de la izquierda de la figura~\ref{fig:AmwDiagram} y es en la que los estudiantes realizan el trabajo en las páginas del wiki. Normlamente, cada grupo de estudiantes tendrá que desarrollar su trabajos en una página del wiki. En la zona más alta de la columna se representa el comienzo del trabajo con una página en blanco. El autor de cada contribución se muestra con una figura de color junto a la misma. Para comenzar, el usuario de color rojo crea una página vacía (\emph{R1}). Después, el usuario azul añade contenido a la página (\emph{R2}). En tercer lugar, el usuario rojo modifica de nuevo la página añadiendo texto a la versión dejada anteriormente por el usuario azul (\emph{R3}) y así sucesivamente. Esta fase termina cuando llega la fecha marcada por el profesor para que los trabajos esten finalizados (\emph{Rf} es la versión final de la página).

Podemos también ver que aunque los estudiantes responsables de la página de ejemplo del wiki fuesen el rojo, el azul y el verde, otros estudiantes como en naranja en la revisión séptima podrían contribuir a la página del wiki. En ese caso, los miembros del grupo decidirían si la contribución debería conservarse o no.

\paragraph*{Evaluación}

Esta fase se muestra en la columna central y comprende las siguientes actividades:

\begin{itemize}
\item \emph{Autoevaluación, evaluación entre iguales y evaluación del profesor}. Las contribuciones a ser evaluadas se asignan a los estudiantes.  Cada contribución es la diferencia entre dos revisiones consecutivas de una página del wiki. El estudiante encargado de evaluar dicha contribución se representa en el gráfico como un usuario coloreado que recibe dos flechas de las revisiones, una de la revisión anterior a la contribución y otra de la revisión que incorpora ya la contribución. Para la evaluación los estudiantes utilizan una rúbirca definida por el profesor. Cada contribución sólo se refiere a una contribución atómica de las realizadas a una página del wiki por un único estudiante, por lo que dicha contribución podría ser utilizada como un indicador de la contribución al wiki de dicho estudiante. El estudiante que realizó cada contribución se representa con una figura pegada a la revisión de la página en cada momento.
Por ejemplo, en la primera evaluación, se asigna la contribución realizada a la página del wiki por el estudiante rojo (\emph{1}) al estudiante azul. El estudiante azul comprueba ambas versiones para ver las diferencias entre ambas versiones (\emph{2}) y realiza la evaluación completando la rúbrica proporcionada por el profesor (\emph{3}).
Cabe destacar también otras situaciones interesante. En la versión \emph{R5} de la página vemos como se realiza una autoevaluación, ya que el estudiante rojo, autor de la versión, es el mismo que tiene que evaluar su contribución. Vemos también que en \emph{R3} es el profesor el que realiza la evaluación de la contribución del estudiante rojo. Esto puede deberse a que el estudiante manualmente detecta una contribución que considera oportuno evaluar o a que utilizando la herramienta SMW detecta un comportamiento extraño en el wiki y quiere contrastar la situación. 
Puede verse también que hay contribuciones que no reciben evaluación alguna, como ocurre con \emph{R6}. Está claro que seria deseable que todas las contribuciones significativas fueran evaluadas, pero no es escalable.
\item \emph{Revisión de las evaluaciones recibidas}. Los estudiantes pueden revisar las evaluaciones recibidas. Ellos pueden no sólo ver las notas que han recibido con las justificaciones y comentarios que añadieron sus evaluadores, sino también el enlace a la contribución. De esta forma, los estudiantes evaluados reciben una retroalimentación formativa. En la primera de las evaluaciones del diagrama de ejemplo puede verse como el estudiante rojo puede ver su evaluación (\emph{4}).
\item \emph{Réplica}. Si el estudiante evaluado no esta de acuerdo con la evaluación recibida tiene la opción de replicarla. Ellos han de explicar la razón de la réplica. En el diagrama de ejemplo puede verse como el estudiante rojo considera injusta su evaluación y realiza una réplica (\emph{5}). El profesor deberá resolver la réplica en la siguiente etapa.
\item \emph{Evaluación final del wiki}. El profesor evalua la versión final de la página del wiki desarrollada por cada grupo de estudiantes. Esta evaluación es necesaria ya que el objetivo principal de la tarea es que los estudiantes realicen un buen trabajo en una página del wiki. Como cualquier otra tarea, debera ser evaluada por el profesor conforme al programa de estudios. Además, algunos de los criterios de evaluación sólo pueden ser evaluados en la versión final de la página, como por ejemplo, la coherencia del texto. De esta forma, aquellas contribuciones del wiki descartadas pr la función de selección serán ahora implíctamente evaluadas ya que están integradas en el entregable final. Podemos ver la evaluación al final del diagrama de ejemplo (\emph{Rf}), y como afecta al grupo de estudiantes completo.
\end{itemize}

El diagrama no recoge algunas situaciones que también podrian darse. Por ejemplo, alguna contribución podría ser evaluada por más de un usuario, ya fuera otro estudiante o el profesor. También, para simplicar, el diagrama sólo muestra una calificación para la contribución (A, A+, B, ... etc.), pero las evaluaciones son multidimensionales.

Un componente interesante de nuestro algoritmo es qué contribución wiki podrá ser asignada a cada estudiante para su evaluación. Es lo que llamamos \emph{función de selección}, y tiene varios aspectos a tener en cuenta:

\begin{itemize}
\item \emph{¿Debería cierta contribución en el wiki ser evaluada por más de un estudiante?} En realidad, tener varias evaluaciones de estudiantes diferentes sobre una misma contribución podría ser interesante para perfeccionar su evaluación y podría proporcionar información al profesor para evaluar no sólo al estudiante autor de la contribución, sino también a los evaluadores. De hecho, el número de contribuciones a ser evaluadas es dependiente del objetivo del experimento y su configuración. Cuánto más grande sea el experimento, más contribuciones susceptibles de ser evaluadas tendrá. Sin embargo, el número de evaluaciones que un estudiante puede realizar es limitado (para que siga siendo formativo). Por lo que cada evaluación adicional a la misma contribución provocará que otras contribuciones sean más pobremente evaluadas o no lo sean.
\item \emph{¿Qué contribuciones deberían ser evaluadas?} La importancia de evaluar cada contribución puede variar. Por ejemplo, evaluar al menos una mínima cantidad de contribuciones por cada estudiante, página o categoría sería interesante. Pero algunas contribuciones que añadan ciertas características al trabajo pueden ser relevantes o informativas sobre el trabajo realizado por un estudiante. Por ejemplo, aunque las contribuciones que añadan gran cantidad de texto suelan ser más interesantes que las contribuciones pequeñas, una contribución pequeña puede ir relacionada con el cambiar el sentido a alguna frase o párrafo. De cualquier forma, un estudiante puede solicitar que una contribución en particular sea evaluada, aunque esta quede fuera de la función de selección.
\item \emph{¿Quién evalúa cada contribución?} Depende de la importancia que se quiera dar a la autoevaluación, la evaluación del compañero y la del profesor. De nuevo, se debería balancear el esfuerzo requerido y el detalle a exigir en las evaluaciones.
\end{itemize}


\paragraph*{Revisión del profesor}

En esta última columna se representan dos actividades que corresponden al profesor:

\begin{itemize}
\item Resolución de las réplicas: el profesor revisa las réplicas indicando si proceden o no. En caso de que procedan, modifica la calificación. En el diagrama se puede ver como en en la primera contribución, el estudiante rojo realiza una réplica (\emph{5}) sobre la evaluación reciba por el usuario azul (\emph{3}). El profesor revisa la réplica, la considera apropiada y modifca la calificación (\emph{6}). En un segundo ejemplo, en la evaluación realizada por el estudiante de color amarillo sobre la contrbución realizada por el usuario de color verde puede verse como el profesor no acepta la réplica realizada por este último, y mantiene la calificación otorgada inicialmente por el estudiante amarillo.
\item Revisión de evaluaciones no replicadas: el profesor puede revisar aleatoriamente otras evaluaciones realizadas por los estudiantes que no hayan sido replicadas. En el diagrama puede verse como en el profesor revisa las evaluaciones realizadas sobre las contribuciones representadas en \emph{R2} y en \emph{R7}, disminuyendo la calificación de la primera y manteniendo la segunda.
\end{itemize}

\subsubsection{Herramienta}

AssessMediaWiki (AMW)~\footnote{http://assessmediawiki.forja.rediris.es} es una aplicación web de código abierto que, al conectarse a una instalación MediaWiki, proporciona procedimientos de autoevaluación, evaluación entre iguales y evaluación del profesor, a la vez que mantiene información sobre esas evaluaciones. AMW pone a disposición de los estudiantes una rubrica previamente definida por el profesor para que realicen la evaluación (figura\ref{fig:AmwRubrica}. 

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.3]{AmwRubrica.png}
  \end{center}
  \caption{Rúbrica de AMW}
  \label{fig:AmwFormative}
\end{figure}

AssessMediaWiki implementa dos roles de usuario distintos: supervisores y estudiantes. Los estudiantes pueden elegir entre distintas opciones: evaluar una revisión, comprobar sus propias aportaciones evaluadas y verificar las evaluaciones ya enviadas. Por otro lado, los supervisores tienen un mayor número de opciones, como definir la rubrica que los estudiantes deberán completar al realizar sus evaluaciones, modificar los parámetros de los programas o vigilar las evaluaciones que los alumnos vayan haciendo. AMW implementa un función de selección parcialmente aleatoria. Cuando un estudiante va a realizar una evaluación, el sistema eligen automáticamente una de entre el 30\percentage más significativa que aún no ha sido evaluada.

Al revisar sus evaluaciones, los estudiantes puede revisar las notas recibidas y sus justificaciones, asi como ver a qué contribución en particular se refiere (figura~\ref{}). Si el estudiante no está de acuerdo con la calificación puede replicar, utilizando para ello una réplica similar a la que se utilizó en su evaluación e indicando las calificaciones que considera que merece y sus correspondientes justificaciones. Después el profesor revisará la disputa y pondra la nota definitica.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.19]{AmwFormative.png}
  \end{center}
  \caption{Ejemplo de retroalimentación formativa y la contribución de wiki evaluada}
  \label{fig:AmwFormative}
\end{figure}



\subsubsection{Indicadores y competencias genéricas}

Los indicadores que se mencionan en este punto han sido utilizados en los estudios de caso realizados para este trabajo, pero como se ha mencionado desde un primer momento, este método proporciona indicadores y es el profesor el que los utilizará para evaluar las competencias genéricas que considere oportunas.

\paragraph*{Trabajo en equipo}
El indicador considerado para el trabajo en equipo es el \emph{ratio de miembros del equipo que trabajaron en un mismo criterio.} La rúbrica que utilizan los estudiantes para evaluar se compone de un conjunto de criterios. Cada criterio puede hacer referencia a una parte del trabajo. En todas las ediciones de un wiki no se trabajan en las mismas partes del trabajo, por lo que al ser evaluado, un estudiante puede tener nota en unos criterios y no tenerla en otros. Si más de un estudiante ha trabajado en la misma parte de una página wiki y su aportación ha sido significativa, tendrán nota en dicho criterio. Por tanto, partiendo de la cantidad de criterios que tiene un trabajo y del ratio de miembros del equipo que ha trabajado en cada criterio tendremos un indicador del trabajo en equipo.

\paragraph*{Comunicación y aplicación del conocimiento}
El indicador considerado para la comunicación y la aplicación del conocimiento es la \emph{media de las notas recibidas por todos los miembros del grupo}. Este indicador mide la incidencia que tuvieron las contribuciones realizadas en el éxito del proyecto. Una calificación pobre en una contribución puede significar  que alguna contribución wiki obtuvo una buena nota en un cierto criterio de la rúbrica pero una mala nota en el otro (el autor soluciona un problema y crea uno nuevo). Probablemente, esto se debió a una mala comunicación entre los miembros del equipo o poco compromiso de un determinado alumno en el objetivo global del grupo. En el enfoque cualitativo esto se mide como el promedio de las calificaciones que todos los miembros del equipo recibieron. 

\paragraph*{Mantener la calidad del trabajo producido}
El indicador considerado para el mantenimiento de la calidad del trabajo producido es la \emph{media de las notas que cada estudiante individualmente recibió}. Unas calificaciones altas en las evaluaciones recibidas puede signifcar que el trabajo que el estudiante está produciendo es de calidad. Si el estudiante produjese mucho contenido, pero este no fuese de calidad, las calificaciones no serían buenas. Es decir, sus calificaciones están teniendo en cuenta el aspecto cualitativo del trabajo y por tanto una nota alta significaría un trabajo de calidad.

\paragraph*{Capacidad crítica}
El indicador considerado para la capacidad crítica es el \emph{número de evaluaciones que el estudiante realizó con respecto al número de dichas evaluaciones cuya nota fue modificada por el profesor}. Este indicador mide la competencia de un estudiante para evaluar el trabajo hecho por otros. Si recibiera un número establecido de réplicas en sus revisiones y estas fueran revisadas por el profesor modificando las calificaciones, podríamos considerar que dicho alumno no ha desempeñado bien dicha competencia.

En la tabla~\ref{tab:ResumenIndicadoresCualiCuanti} puede verse una comparación entre los indicadores considerados a partir de la evaluación cualitativa y los que se obtenien a partir de la evaluación cuantitativa.

\begin{table}
  \begin{center}
  \begin{tabular}{| m{3.2cm} | m{4.9cm} | m{5.1cm} |}
    \hline 
    \multirow{2}{*}{COMPETENCIAS}  & INDICADORES  & INDICADORES  \\
      &  CUALITATIVOS  &  CUANTITATIVOS \\
    \hline
    \hline
    Trabajo en equipo  & Ratio de miembros del equipo que trabajaron en un mismo criterio  & Ratio de miembros del equipo que contribuyeron a una misma página del wiki en las páginas de su proyecto \\
    \hline
    Comunicación y aplicación del conocimiento  & Media de las notas recibidas por todos los miembros del grupo  & Porcentaje de miembros del equipo que contribuyeron al menos a un 20\percentage del trabajo realizado \\
    \hline
    Mantener la calidad del trabajo producido  & Media de las notas que cada estudiante individualmente recibió  & Contribución individual en bytes \\
    \hline
    Capacidad crítica  & Número de evaluaciones que el estudiante realizó con respecto al número de dichas evaluaciones cuya nota fue modificada por el profesor  & No considerada \\
    \hline
  \end{tabular}
\end{center}
\caption{Resumen de las competencias evaluadas para cada tipo de indicador}
\label{tab:ResumenIndicadoresCualiCuanti}
\end{table} 

%\subsubsection{Ejemplo de uso}

%El ejemplo de uso podrá verse en el estudio de caso que se muestra en el siguiente capítulo.
%\subsubsection{Publicación}

%Un trabajo con AMW fue publicado en SPDECE 2012~\cite{Balderas:2012}.
% La evaluación de las 3 herramientas se corresponde al capítulo siguiente.

%------------------------------------------------
\subsection{LMS: EvalCourse}

Esta segunda propuesta se aplica en los cursos virtuales (LMS, del inglés \emph{learning management system}). Los LMSs registran todo lo que hacen los estudiantes en el sistema: archivos descargados, accesos a los foros o tareas enviadas. En esta propuesta se utilizarán indicadores obtenidos del análisis de los procesos de aprendizaje realizados por los estudiantes en el LMS para la evaluación de sus competencias genéricas.

\subsubsection{Método}

Para evaluar las competencias genéricas, el profesor deberá definir los indicadores que serán extraidos de la actividad de cada estudiante en el LMS. Ilustraremos el método a partir de un ejemplo de uso de EvalCourse y su ejecución con los foros del LMS. Los foros suelen ser una de las herramientas incorporadas por los LMSs para la interacción entre los estudiantes. Es evidente que la comunicación oral es una manera muy rica de comunicarse, que proporciona múltiples signos no verbales como las expresiones faciales o el tono de voz. En contraste, las comunicaciones escritas proporcionan otras ventajas. Una de las más importantes para la educación es que el estudiante dispone de un tiempo para la relfexión. Por esta razon, podría preferirse la comunicación escrita a la oral cuando se busca un aprendizaje cognitivo~\cite{garrison1999critical}.

El profesor deberá crear en el LMS las actividades que le puedan proporcionar los indicadores. Estos indicadores deben ser publicados para que los estudiantes sepan cómo seran evaluados. Durante el curso, los estudiantes interactuarán con el LMS conforme a las instrucciones proporcionadas por sus profesores. Cuando lo desee, el profesor podrá utilizar EvalCourse para obtener los indicadroes.

La obtención de indicadores se basara en el \emph{ciclo de contraste de hipótesis}. Es decir, el profesor podrá diseñar una evaluación y obtendrá los resultados. Si los resultados no son válidos como indicadores de la competencia, entonces el profesor podra rediseñar la evaluación. En cualquier caso, el profesor podrá reutilizar el diseño cuántas veces sea necesaria a lo largo del curso y monitorizar la evolución de los indicadores de cada estudiante.

\subsubsection{EvalCourse DSL}

Para obtener los indicadores del LMS se creó un lenguaje especifico de dominio (DSL, del inglés \emph{domain-specific language}). Los profesores que utilizasen el lenguaje, escribirían una consulta sencilla con términos cercanos al dominio educativo y recibirían como respuesta la información solicitada en la consulta. 

\subsubsection{Indicadores que aporta}

bla bla bla

\subsubsection{Ejemplo de uso}

bla bla bla

\subsubsection{Publicación}

bla bla bla
% La evaluación de las 3 herramientas se corresponde al capítulo siguiente.

%------------------------------------------------
\subsection{Mundos virtuales: EvalSim}

Aunque muchos investigadores han reconocido la potencia educativa y motivacional de los videojuegos, hay pocos estudios empíricos que hayan investigado recientemente su impacto en el aprendizaje de los estudiantes~\cite{berns2013game}. Lo mismo se puede decir de los entornos de aprendizaje como los mundos virtuales (Second Life, OpenCobalt, etc.)~\cite{hew2010use}. Esto se debe en gran parte a que estos entornos no suelen tener licencias libres y, por consiguiente, los profesores no pueden diseñar sus propios entornos, analizar las interacciones de los estudiantes o analizar su impacto en el aprendizaje y en los resultados de aprendizaje~\cite{cruz2015discovering,moreno2014serious}. Por tanto, finalmente optamos por construir nuestro propio mundo virtual, basado en OpenSim (software de código abierto), para poder analizar después los procesos de aprendizaje.

\subsubsection{Metodología}

En el juego los estudiantes interactúan entre ellos por medio de un chat. Las conversaciones quedan almancenadas en la base de datos de EvalSim. Utilizando el ciclo de contraste de hipótesis los profesores obtendrán indicadores del trabajo de sus estudiantes (figura~\ref{fig:EvalSimArchitecture}).

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.29]{EvalSimArchitecture.png}
  \end{center}
  \caption{Ciclo de contraste de hipótesis con EvalSim}
  \label{fig:EvalSimArchitecture}
\end{figure}

El profesor diseña una evaluación (\emph{a}) que bajo su criterio le vaya a proporcionar indicadores válidos para evaluar alguna competencia genérica y la envía a EvalSim (\emph{b}). EvalSim procesa la petición y realiza la solicitud a la base de datos del mundo virtual (\emph{c}) . Una vez que recibe los datos (\emph{d}), los transforma y devuelve los resultados debidamente formateados al profesor (\emph{e}). El profesor los analiza, y si considera que son indicadores válidos para evaluar la competencia (\emph{f}) termina el ciclo. Sin embargo, si entiende que no les sirven o considera que deberia refinarlo podría volver a diseñar una nueva evaluación (\emph{g}), reinciándose de nuevo el ciclo.

\subsubsection{Tecnología implementada}

% Habrá que citar antes el MDD {schmidt2006guest} // artículo citado en evalsims. Borrar este comentario al citar
Para este trabajo se creó VWQL (\emph{Virtual Worl Query language}). VWQL es un DSL creado para obtener indicadores objetivos de OpenSim. EvalSim es el sistema que procesa las consultas de VWQL. Ha sido desarrollado bajo un enfoque dirigido por modelos para modelar procesos para obtener los indicadores que se requieran. Fue implementado utilizando Xtext~\cite{eysholdt2010xtext} dentro del Eclipse Modeling Framework, que se distribuye como software de codigo abierto bajo licencia GNU.

La sintaxis del lenguaje (versión beta 0.1) y pueden verse en~\ref{code:reserved}. La primera línea especifica el nombre del indicador (\emph{name\_of\_the\_indicator}) y se utiliza para diferenciar los diferentes archivos producidos por EvalSim. La segunda línea comienza obligatoriamente con \emph{get students} y a continuación se ha de especificas si se quiere obtener la información para todos los estudiantes que participaron en la experiencia o para sólo algunos de los que participaron (indicando sus identificadores numéricos de usuario). La última línea indica el tipo de información a extraer tras el término obligatorio \emph{show} y esta información puede ser alguno de los siguientes tipos:

\begin{itemize}
\item \emph{words}: número de palabras escritas en el chat de texto. Por defecto cuenta todas las palabras, a no ser que se indique un idioma, en cuyo caso únicamente muestra de las palabras introducidas en el chat de texto, las palabras en dicho idioma.
\item \emph{sentences}: número de frases escritas en el chat de texto.
\item \emph{single}: número de frases basadas en una sola palabra escritas en el chat de texto.
\item \emph{turns}: número de turnos realizados en chat de texto. Un turno es un conjunto de frases consecutivas escritas por el mismo usuario.
\item \emph{time}: número de minutos jugados en el mundo virtual.
\item \emph{points}: número de puntos obtenidos en el mundo virtual. La manera en que los puntos se obtengan dependerá específicamente del mundo virtual jugado.
\end{itemize}

\begin{lstlisting}[caption=Palabras reservadas y formato de VWQL (version 0.1), label=code:reserved,numbers=left, captionpos=b, morekeywords={Evidence,get, students, show, words, sentences, turns, time, points}]
Evidence name_of_the_evidence:
    get students [id_of_the_student]
    show ( words [dict] | sentences | turns |
         | time | points )+
\end{lstlisting}

\subsubsection{Indicadores}

El mundo virtual se ha desarrollado para asignaturas de idiomas, por lo que la competencia genérica que se ha evaluado con los indicadores obtenidos ha sido la \emph{habilidad para comunicarse en un segundo idioma}. Estos indicadores son:

% Hipótesis: un estudiante tiene dificultades para hacerse entender si necesita dos o más frases por turno para comunicarse con su compañero.

\begin{itemize}
\item \emph{Ritmo}: número de frases escritas por minuto.
\item \emph{Frases por turno}: número de frases escritas por turno.
\end{itemize}

\subsubsection{Ejemplo de uso}

bla bla bla

% La evaluación de las 3 herramientas se corresponde al capítulo siguiente.


%Metolodogía mixta

%Cómo voy a evaluar roles, momentos, actividad, ... lo que sea.

%Explicar el DSL

%DSL: herramienta de investigación en evaluaciones. Esta herramienta ayuda al investigador a formalizar la evaluación.
 
%Enfocar la metodología a que no es una metodología para evaluar, sino para diseñar evaluaciones. Diseñador de evaluaciones.

%Explicar qué pasos tiene que seguir un diseñador de evaluaciones para hacer sus evaluaciones.

%Dentro de los resultados obtenemos dos cosas:
%1. Diseño
%2. Lo que el diseñador nos indicó que no pudo hacer

%Para que esto sea posible falta la herramienta informática

%\section{Evolución herramientas}

%AMW --> EvalCourse --> EvalSim

%\section{Metodologia de desarrollo}

%DSL? Ing. Dirigida x modelo?



% ----------------------------------------------------------------------

